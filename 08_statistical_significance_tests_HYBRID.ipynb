{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Significance Testing for Topic-Based Forecasts\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook performs rigorous statistical testing of forecast results from notebook 07.\n",
    "\n",
    "**Tests Applied:**\n",
    "1. **One-Sided Diebold-Mariano** → Tests if ARIMAX significantly outperforms ARIMA\n",
    "2. **Sign Test** → Tests fold-level consistency (do topics help in majority of folds?)\n",
    "3. **Wilcoxon Signed-Rank** → Non-parametric test robust to outliers\n",
    "4. **Bootstrap Diebold-Mariano** → Better small-sample properties\n",
    "5. **Clark-West Test** → Adjusts for nested models (ARIMAX contains ARIMA)\n",
    "\n",
    "**Why Multiple Tests?**\n",
    "- Small sample (n=20 forecasts) requires robust evidence\n",
    "- Each test has different strengths\n",
    "- Convergence across tests = stronger conclusion\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical testing\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_rel, wilcoxon, binomtest, norm\n",
    "\n",
    "# Visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\" Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Load Forecast Results from Notebook 07\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADED HYBRID RESULTS\n",
      "================================================================================\n",
      "\n",
      "d=0 (Forecasting Performance):\n",
      "  K=6:  62 models\n",
      "  K=25: 34 models\n",
      "\n",
      "d=1 (Causal Robustness):\n",
      "  K=6:  11 models\n",
      "  K=25: 11 models\n",
      "\n",
      "Cross-validation folds: 10\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load HYBRID results (both d=0 and d=1)\n",
    "with open('results/forecast_results_HYBRID.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Extract d=0 (Forecasting)\n",
    "results_k6_d0 = data['results_k6_d0']\n",
    "results_k25_d0 = data['results_k25_d0']\n",
    "summary_k6_d0 = data['summary_k6_d0']\n",
    "summary_k25_d0 = data['summary_k25_d0']\n",
    "\n",
    "# Extract d=1 (Causality)\n",
    "results_k6_d1 = data['results_k6_d1']\n",
    "results_k25_d1 = data['results_k25_d1']\n",
    "summary_k6_d1 = data['summary_k6_d1']\n",
    "summary_k25_d1 = data['summary_k25_d1']\n",
    "\n",
    "# Metadata\n",
    "cv_splits = data['cv_splits']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADED HYBRID RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nd=0 (Forecasting Performance):\")\n",
    "print(f\"  K=6:  {len(results_k6_d0)} models\")\n",
    "print(f\"  K=25: {len(results_k25_d0)} models\")\n",
    "\n",
    "print(f\"\\nd=1 (Causal Robustness):\")\n",
    "print(f\"  K=6:  {len(results_k6_d1)} models\")\n",
    "print(f\"  K=25: {len(results_k25_d1)} models\")\n",
    "\n",
    "print(f\"\\nCross-validation folds: {len(cv_splits)}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Statistical Test Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All statistical test functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEST 1: ONE-SIDED DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "\n",
    "def diebold_mariano_one_sided(residuals_baseline, residuals_model):\n",
    "    \"\"\"\n",
    "    One-sided Diebold-Mariano test\n",
    "    \n",
    "    H0: Model is NOT better than baseline\n",
    "    H1: Model IS better than baseline (smaller MSE)\n",
    "    \n",
    "    Returns:\n",
    "        dm_stat: Positive if model is better\n",
    "        p_value: One-sided p-value (small = significant improvement)\n",
    "    \"\"\"\n",
    "    # Loss differential (positive when model beats baseline)\n",
    "    d = residuals_baseline**2 - residuals_model**2\n",
    "    \n",
    "    mean_d = np.mean(d)\n",
    "    var_d = np.var(d, ddof=1)\n",
    "    \n",
    "    if var_d == 0 or len(d) < 2:\n",
    "        return 0.0, 1.0\n",
    "    \n",
    "    # DM statistic\n",
    "    dm_stat = mean_d / np.sqrt(var_d / len(d))\n",
    "    \n",
    "    # One-tailed test (model is better if dm_stat > 0)\n",
    "    p_value = 1 - stats.t.cdf(dm_stat, df=len(d)-1)\n",
    "    \n",
    "    return dm_stat, p_value\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 2: SIGN TEST\n",
    "# ============================================================================\n",
    "\n",
    "def sign_test_folds(results_baseline, results_model):\n",
    "    \"\"\"\n",
    "    Test if model beats baseline in majority of CV folds\n",
    "    \n",
    "    H0: Model wins 50% of folds (random)\n",
    "    H1: Model wins > 50% of folds\n",
    "    \n",
    "    Returns:\n",
    "        wins: Number of folds where model beats baseline\n",
    "        total: Total folds\n",
    "        p_value: Binomial test p-value\n",
    "    \"\"\"\n",
    "    n_folds = len(results_baseline)\n",
    "    wins = sum(1 for i in range(n_folds) \n",
    "               if results_model[i]['rmse'] < results_baseline[i]['rmse'])\n",
    "    \n",
    "    # One-sided binomial test\n",
    "    result = binomtest(wins, n_folds, 0.5, alternative='greater')\n",
    "    \n",
    "    return wins, n_folds, result.pvalue\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 3: WILCOXON SIGNED-RANK\n",
    "# ============================================================================\n",
    "\n",
    "def wilcoxon_test(residuals_baseline, residuals_model):\n",
    "    \"\"\"\n",
    "    Wilcoxon signed-rank test on absolute errors\n",
    "    \n",
    "    Non-parametric alternative to paired t-test\n",
    "    Robust to outliers and non-normal distributions\n",
    "    \n",
    "    H0: Median absolute errors are equal\n",
    "    H1: Model has smaller median absolute error\n",
    "    \"\"\"\n",
    "    abs_err_baseline = np.abs(residuals_baseline)\n",
    "    abs_err_model = np.abs(residuals_model)\n",
    "    \n",
    "    try:\n",
    "        stat, p_value = wilcoxon(abs_err_baseline, abs_err_model, \n",
    "                                 alternative='greater', zero_method='wilcox')\n",
    "        return stat, p_value\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 4: BOOTSTRAP DIEBOLD-MARIANO\n",
    "# ============================================================================\n",
    "\n",
    "def bootstrap_dm_test(residuals_baseline, residuals_model, n_boot=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Bootstrap version of DM test for better small-sample inference\n",
    "    \n",
    "    Uses resampling to estimate p-value without relying on \n",
    "    asymptotic normal approximation\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Observed statistic\n",
    "    d_obs = residuals_baseline**2 - residuals_model**2\n",
    "    mean_obs = d_obs.mean()\n",
    "    \n",
    "    # Bootstrap distribution under null (center at zero)\n",
    "    d_centered = d_obs - mean_obs\n",
    "    boot_means = []\n",
    "    \n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(len(d_centered), size=len(d_centered), replace=True)\n",
    "        boot_means.append(d_centered[idx].mean())\n",
    "    \n",
    "    boot_means = np.array(boot_means)\n",
    "    \n",
    "    # One-sided p-value\n",
    "    p_value = (boot_means >= mean_obs).mean()\n",
    "    \n",
    "    return mean_obs, p_value\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 5: CLARK-WEST TEST\n",
    "# ============================================================================\n",
    "\n",
    "def clark_west_test(residuals_baseline, residuals_model, \n",
    "                    forecast_baseline, forecast_model):\n",
    "    \"\"\"\n",
    "    Clark-West test for nested models\n",
    "    \n",
    "    Adjusts DM test for the fact that ARIMAX has more parameters than ARIMA\n",
    "    Standard DM test is too conservative for nested models\n",
    "    \n",
    "    H0: Baseline is adequate\n",
    "    H1: Additional parameters (topics) improve fit\n",
    "    \"\"\"\n",
    "    n = len(residuals_baseline)\n",
    "    \n",
    "    mse_baseline = residuals_baseline**2\n",
    "    mse_model = residuals_model**2\n",
    "    \n",
    "    # Adjustment for nested models\n",
    "    adjustment = (forecast_baseline - forecast_model)**2\n",
    "    \n",
    "    # CW statistic\n",
    "    f_bar = (mse_baseline - mse_model + adjustment).mean()\n",
    "    var_f = (mse_baseline - mse_model + adjustment).var(ddof=1)\n",
    "    \n",
    "    if var_f == 0 or n < 2:\n",
    "        return 0.0, 1.0\n",
    "    \n",
    "    cw_stat = f_bar / np.sqrt(var_f / n)\n",
    "    \n",
    "    # One-sided test (use normal approximation)\n",
    "    p_value = 1 - norm.cdf(cw_stat)\n",
    "    \n",
    "    return cw_stat, p_value\n",
    "\n",
    "print(\"All statistical test functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Run All Tests on K=6 Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RUNNING STATISTICAL TESTS: K=6 MODELS\n",
      "================================================================================\n",
      "\n",
      "Testing 61 models against baseline...\n",
      "\n",
      "[ 1/61] Testing K6_T2                     → 0/5 tests significant\n",
      "[ 2/61] Testing K6_T3                     → 4/5 tests significant\n",
      "[ 3/61] Testing K6_T4                     → 0/5 tests significant\n",
      "[ 4/61] Testing K6_T5                     → 1/5 tests significant\n",
      "[ 5/61] Testing K6_T6                     → 4/5 tests significant\n",
      "[ 6/61] Testing K6_T1_T3                  → 0/5 tests significant\n",
      "[ 7/61] Testing K6_T1_T4                  → 0/5 tests significant\n",
      "[ 8/61] Testing K6_T1_T5                  → 0/5 tests significant\n",
      "[ 9/61] Testing K6_T1_T6                  → 4/5 tests significant\n",
      "[10/61] Testing K6_T2_T3                  → 4/5 tests significant\n",
      "[11/61] Testing K6_T2_T4                  → 0/5 tests significant\n",
      "[12/61] Testing K6_T2_T5                  → 2/5 tests significant\n",
      "[13/61] Testing K6_T2_T6                  → 4/5 tests significant\n",
      "[14/61] Testing K6_T3_T4                  → 4/5 tests significant\n",
      "[15/61] Testing K6_T3_T5                  → 4/5 tests significant\n",
      "[16/61] Testing K6_T3_T6                  → 5/5 tests significant\n",
      "[17/61] Testing K6_T4_T5                  → 1/5 tests significant\n",
      "[18/61] Testing K6_T4_T6                  → 4/5 tests significant\n",
      "[19/61] Testing K6_T5_T6                  → 4/5 tests significant\n",
      "[20/61] Testing K6_T1_T2_T3               → 4/5 tests significant\n",
      "[21/61] Testing K6_T1_T2_T4               → 0/5 tests significant\n",
      "[22/61] Testing K6_T1_T2_T5               → 0/5 tests significant\n",
      "[23/61] Testing K6_T1_T2_T6               → 4/5 tests significant\n",
      "[24/61] Testing K6_T1_T3_T4               → 1/5 tests significant\n",
      "[25/61] Testing K6_T1_T3_T5               → 2/5 tests significant\n",
      "[26/61] Testing K6_T1_T3_T6               → 5/5 tests significant\n",
      "[27/61] Testing K6_T1_T4_T5               → 1/5 tests significant\n",
      "[28/61] Testing K6_T1_T4_T6               → 4/5 tests significant\n",
      "[29/61] Testing K6_T1_T5_T6               → 4/5 tests significant\n",
      "[30/61] Testing K6_T2_T3_T4               → 4/5 tests significant\n",
      "[31/61] Testing K6_T2_T3_T5               → 4/5 tests significant\n",
      "[32/61] Testing K6_T2_T3_T6               → 5/5 tests significant\n",
      "[33/61] Testing K6_T2_T4_T5               → 1/5 tests significant\n",
      "[34/61] Testing K6_T2_T4_T6               → 4/5 tests significant\n",
      "[35/61] Testing K6_T2_T5_T6               → 4/5 tests significant\n",
      "[36/61] Testing K6_T3_T4_T5               → 2/5 tests significant\n",
      "[37/61] Testing K6_T3_T4_T6               → 5/5 tests significant\n",
      "[38/61] Testing K6_T3_T5_T6               → 5/5 tests significant\n",
      "[39/61] Testing K6_T4_T5_T6               → 4/5 tests significant\n",
      "[40/61] Testing K6_T1_T2_T3_T4            → 4/5 tests significant\n",
      "[41/61] Testing K6_T1_T2_T3_T5            → 4/5 tests significant\n",
      "[42/61] Testing K6_T1_T2_T3_T6            → 5/5 tests significant\n",
      "[43/61] Testing K6_T1_T2_T4_T5            → 1/5 tests significant\n",
      "[44/61] Testing K6_T1_T2_T4_T6            → 4/5 tests significant\n",
      "[45/61] Testing K6_T1_T2_T5_T6            → 4/5 tests significant\n",
      "[46/61] Testing K6_T1_T3_T4_T5            → 1/5 tests significant\n",
      "[47/61] Testing K6_T1_T3_T4_T6            → 5/5 tests significant\n",
      "[48/61] Testing K6_T1_T3_T5_T6            → 5/5 tests significant\n",
      "[49/61] Testing K6_T1_T4_T5_T6            → 4/5 tests significant\n",
      "[50/61] Testing K6_T2_T3_T4_T5            → 4/5 tests significant\n",
      "[51/61] Testing K6_T2_T3_T4_T6            → 5/5 tests significant\n",
      "[52/61] Testing K6_T2_T3_T5_T6            → 5/5 tests significant\n",
      "[53/61] Testing K6_T2_T4_T5_T6            → 4/5 tests significant\n",
      "[54/61] Testing K6_T3_T4_T5_T6            → 5/5 tests significant\n",
      "[55/61] Testing K6_T1_T2_T3_T4_T5         → 5/5 tests significant\n",
      "[56/61] Testing K6_T1_T2_T3_T4_T6         → 5/5 tests significant\n",
      "[57/61] Testing K6_T1_T2_T3_T5_T6         → 5/5 tests significant\n",
      "[58/61] Testing K6_T1_T2_T4_T5_T6         → 5/5 tests significant\n",
      "[59/61] Testing K6_T1_T3_T4_T5_T6         → 5/5 tests significant\n",
      "[60/61] Testing K6_T2_T3_T4_T5_T6         → 5/5 tests significant\n",
      "[61/61] Testing K6_T1_T2_T3_T4_T5_T6      → 5/5 tests significant\n",
      "\n",
      " K=6 testing complete\n",
      "  Models with ANY significant test: 53/61\n",
      "  Models with MAJORITY significant (3+): 43/61\n"
     ]
    }
   ],
   "source": [
    "def run_all_tests(results_baseline, results_model, model_name):\n",
    "    \"\"\"\n",
    "    Run all 5 statistical tests on a model\n",
    "    \n",
    "    Returns dict with test results\n",
    "    \"\"\"\n",
    "    # Collect data - compute residuals if not present\n",
    "    residuals_baseline = []\n",
    "    residuals_model = []\n",
    "    forecast_baseline = []\n",
    "    forecast_model = []\n",
    "    \n",
    "    for r in results_baseline:\n",
    "        if 'residuals' in r:\n",
    "            residuals_baseline.append(r['residuals'])\n",
    "        else:\n",
    "            residuals_baseline.append(r['actual'] - r['forecast'])\n",
    "        forecast_baseline.append(r['forecast'])\n",
    "    \n",
    "    for r in results_model:\n",
    "        if 'residuals' in r:\n",
    "            residuals_model.append(r['residuals'])\n",
    "        else:\n",
    "            residuals_model.append(r['actual'] - r['forecast'])\n",
    "        forecast_model.append(r['forecast'])\n",
    "    \n",
    "    residuals_baseline = np.concatenate(residuals_baseline)\n",
    "    residuals_model = np.concatenate(residuals_model)\n",
    "    forecast_baseline = np.concatenate(forecast_baseline)\n",
    "    forecast_model = np.concatenate(forecast_model)\n",
    "    \n",
    "    # Test 1: One-sided DM\n",
    "    dm_stat, dm_p = diebold_mariano_one_sided(residuals_baseline, residuals_model)\n",
    "    \n",
    "    # Test 2: Sign test\n",
    "    wins, total, sign_p = sign_test_folds(results_baseline, results_model)\n",
    "    \n",
    "    # Test 3: Wilcoxon\n",
    "    wilc_stat, wilc_p = wilcoxon_test(residuals_baseline, residuals_model)\n",
    "    \n",
    "    # Test 4: Bootstrap DM\n",
    "    boot_stat, boot_p = bootstrap_dm_test(residuals_baseline, residuals_model)\n",
    "    \n",
    "    # Test 5: Clark-West\n",
    "    cw_stat, cw_p = clark_west_test(residuals_baseline, residuals_model,\n",
    "                                     forecast_baseline, forecast_model)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    rmse_baseline = np.sqrt(np.mean(residuals_baseline**2))\n",
    "    rmse_model = np.sqrt(np.mean(residuals_model**2))\n",
    "    improvement_pct = (rmse_baseline - rmse_model) / rmse_baseline * 100\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'rmse_baseline': rmse_baseline,\n",
    "        'rmse_model': rmse_model,\n",
    "        'improvement_%': improvement_pct,\n",
    "        'folds_better': f\"{wins}/{total}\",\n",
    "        'win_rate': wins/total,\n",
    "        'dm_stat': dm_stat,\n",
    "        'dm_p': dm_p,\n",
    "        'sign_p': sign_p,\n",
    "        'wilcoxon_p': wilc_p,\n",
    "        'bootstrap_p': boot_p,\n",
    "        'clarkwest_p': cw_p,\n",
    "        'dm_sig': dm_p < 0.05,\n",
    "        'sign_sig': sign_p < 0.05,\n",
    "        'wilcoxon_sig': wilc_p < 0.05 if not np.isnan(wilc_p) else False,\n",
    "        'bootstrap_sig': boot_p < 0.05,\n",
    "        'clarkwest_sig': cw_p < 0.05,\n",
    "        'n_tests_sig': sum([\n",
    "            dm_p < 0.05,\n",
    "            sign_p < 0.05,\n",
    "            wilc_p < 0.05 if not np.isnan(wilc_p) else False,\n",
    "            boot_p < 0.05,\n",
    "            cw_p < 0.05\n",
    "        ])\n",
    "    }\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RUNNING STATISTICAL TESTS: K=6 MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTesting {len(results_k6_d0)-1} models against baseline...\\n\")\n",
    "\n",
    "test_results_k6_d0 = []\n",
    "baseline_k6_d0 = results_k6_d0['Baseline']\n",
    "\n",
    "for i, (model_name, model_results) in enumerate(results_k6_d0.items(), 1):\n",
    "    if model_name == 'Baseline':\n",
    "        continue\n",
    "    \n",
    "    print(f\"[{i-1:2d}/{len(results_k6_d0)-1}] Testing {model_name:25s}\", end=\" \")\n",
    "    \n",
    "    test_result = run_all_tests(baseline_k6_d0, model_results, model_name)\n",
    "    test_results_k6_d0.append(test_result)\n",
    "    \n",
    "    sig_count = test_result['n_tests_sig']\n",
    "    print(f\"→ {sig_count}/5 tests significant\")\n",
    "\n",
    "df_tests_k6_d0 = pd.DataFrame(test_results_k6_d0)\n",
    "df_tests_k6_d0 = df_tests_k6_d0.sort_values('n_tests_sig', ascending=False)\n",
    "\n",
    "print(f\"\\n K=6 testing complete\")\n",
    "print(f\"  Models with ANY significant test: {(df_tests_k6_d0['n_tests_sig'] > 0).sum()}/{len(df_tests_k6_d0)}\")\n",
    "print(f\"  Models with MAJORITY significant (3+): {(df_tests_k6_d0['n_tests_sig'] >= 3).sum()}/{len(df_tests_k6_d0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Run All Tests on K=25 Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RUNNING STATISTICAL TESTS: K=25 MODELS\n",
      "================================================================================\n",
      "\n",
      "Testing 33 models against baseline...\n",
      "\n",
      "[ 1/33] Testing K25_T1                    → 0/5 tests significant\n",
      "[ 2/33] Testing K25_T4                    → 0/5 tests significant\n",
      "[ 3/33] Testing K25_T7                    → 0/5 tests significant\n",
      "[ 4/33] Testing K25_T8                    → 0/5 tests significant\n",
      "[ 5/33] Testing K25_T9                    → 0/5 tests significant\n",
      "[ 6/33] Testing K25_T10                   → 4/5 tests significant\n",
      "[ 7/33] Testing K25_T15                   → 0/5 tests significant\n",
      "[ 8/33] Testing K25_T20                   → 0/5 tests significant\n",
      "[ 9/33] Testing K25_T24                   → 4/5 tests significant\n",
      "[10/33] Testing K25_T1_T10                → 0/5 tests significant\n",
      "[11/33] Testing K25_T1_T24                → 0/5 tests significant\n",
      "[12/33] Testing K25_T1_T17                → 0/5 tests significant\n",
      "[13/33] Testing K25_T1_T20                → 0/5 tests significant\n",
      "[14/33] Testing K25_T10_T24               → 4/5 tests significant\n",
      "[15/33] Testing K25_T10_T17               → 4/5 tests significant\n",
      "[16/33] Testing K25_T10_T20               → 5/5 tests significant\n",
      "[17/33] Testing K25_T10_T11               → 0/5 tests significant\n",
      "[18/33] Testing K25_T10_T13               → 0/5 tests significant\n",
      "[19/33] Testing K25_T10_T23               → 0/5 tests significant\n",
      "[20/33] Testing K25_T17_T24               → 3/5 tests significant\n",
      "[21/33] Testing K25_T20_T24               → 0/5 tests significant\n",
      "[22/33] Testing K25_T23_T24               → 0/5 tests significant\n",
      "[23/33] Testing K25_T17_T20               → 0/5 tests significant\n",
      "[24/33] Testing K25_T11_T20               → 0/5 tests significant\n",
      "[25/33] Testing K25_T1_T10_T24            → 1/5 tests significant\n",
      "[26/33] Testing K25_T1_T10_T17            → 0/5 tests significant\n",
      "[27/33] Testing K25_T1_T17_T24            → 0/5 tests significant\n",
      "[28/33] Testing K25_T10_T12_T24           → 0/5 tests significant\n",
      "[29/33] Testing K25_T10_T17_T24           → 4/5 tests significant\n",
      "[30/33] Testing K25_Granger_Top3          → 0/5 tests significant\n",
      "[31/33] Testing K25_Granger_Top5          → 0/5 tests significant\n",
      "[32/33] Testing K25_LASSO_Top3            → 0/5 tests significant\n",
      "[33/33] Testing K25_LASSO_Top5            → 0/5 tests significant\n",
      "\n",
      " K=25 testing complete\n",
      "  Models with ANY significant test: 8/33\n",
      "  Models with MAJORITY significant (3+): 7/33\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RUNNING STATISTICAL TESTS: K=25 MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTesting {len(results_k25_d0)-1} models against baseline...\\n\")\n",
    "\n",
    "test_results_k25_d0 = []\n",
    "baseline_k25_d0 = results_k25_d0['Baseline']\n",
    "\n",
    "for i, (model_name, model_results) in enumerate(results_k25_d0.items(), 1):\n",
    "    if model_name == 'Baseline':\n",
    "        continue\n",
    "    \n",
    "    print(f\"[{i-1:2d}/{len(results_k25_d0)-1}] Testing {model_name:25s}\", end=\" \")\n",
    "    \n",
    "    test_result = run_all_tests(baseline_k25_d0, model_results, model_name)\n",
    "    test_results_k25_d0.append(test_result)\n",
    "    \n",
    "    sig_count = test_result['n_tests_sig']\n",
    "    print(f\"→ {sig_count}/5 tests significant\")\n",
    "\n",
    "df_tests_k25_d0 = pd.DataFrame(test_results_k25_d0)\n",
    "df_tests_k25_d0 = df_tests_k25_d0.sort_values('n_tests_sig', ascending=False)\n",
    "\n",
    "print(f\"\\n K=25 testing complete\")\n",
    "print(f\"  Models with ANY significant test: {(df_tests_k25_d0['n_tests_sig'] > 0).sum()}/{len(df_tests_k25_d0)}\")\n",
    "print(f\"  Models with MAJORITY significant (3+): {(df_tests_k25_d0['n_tests_sig'] >= 3).sum()}/{len(df_tests_k25_d0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Detailed Results Tables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STATISTICAL TEST RESULTS: K=6 (Top 10 Models)\n",
      "================================================================================\n",
      "\n",
      "               model  improvement_% folds_better  n_tests_sig     dm_p   sign_p  wilcoxon_p  bootstrap_p  clarkwest_p\n",
      "K6_T1_T2_T3_T4_T5_T6       8.791416         9/10            5 0.003960 0.010742    0.000931        0.008     0.000516\n",
      "      K6_T2_T3_T5_T6       9.931547         9/10            5 0.002460 0.010742    0.000422        0.005     0.000298\n",
      "         K6_T1_T3_T6       8.765706         9/10            5 0.004683 0.010742    0.000422        0.008     0.001221\n",
      "         K6_T3_T4_T6       8.628277         9/10            5 0.005731 0.010742    0.000649        0.014     0.001205\n",
      "         K6_T3_T5_T6       9.859040         9/10            5 0.002948 0.010742    0.000553        0.006     0.000605\n",
      "      K6_T1_T2_T3_T6       9.391227         9/10            5 0.002801 0.010742    0.000240        0.006     0.000332\n",
      "      K6_T1_T3_T4_T6       8.285513         9/10            5 0.006770 0.010742    0.001454        0.013     0.001566\n",
      "            K6_T3_T6       9.492087        10/10            5 0.003371 0.000977    0.000319        0.007     0.000735\n",
      "      K6_T2_T3_T4_T6       9.474133         9/10            5 0.002525 0.010742    0.000584        0.006     0.000238\n",
      "      K6_T1_T3_T5_T6       9.172950         9/10            5 0.003659 0.010742    0.000759        0.007     0.000870\n",
      "\n",
      "================================================================================\n",
      "Significance Summary (p < 0.05):\n",
      "================================================================================\n",
      "\n",
      "               model  dm_sig  sign_sig  wilcoxon_sig  bootstrap_sig  clarkwest_sig  n_tests_sig\n",
      "K6_T1_T2_T3_T4_T5_T6    True      True          True           True           True            5\n",
      "      K6_T2_T3_T5_T6    True      True          True           True           True            5\n",
      "         K6_T1_T3_T6    True      True          True           True           True            5\n",
      "         K6_T3_T4_T6    True      True          True           True           True            5\n",
      "         K6_T3_T5_T6    True      True          True           True           True            5\n",
      "      K6_T1_T2_T3_T6    True      True          True           True           True            5\n",
      "      K6_T1_T3_T4_T6    True      True          True           True           True            5\n",
      "            K6_T3_T6    True      True          True           True           True            5\n",
      "      K6_T2_T3_T4_T6    True      True          True           True           True            5\n",
      "      K6_T1_T3_T5_T6    True      True          True           True           True            5\n"
     ]
    }
   ],
   "source": [
    "# K=6 Results\n",
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL TEST RESULTS: K=6 (Top 10 Models)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "display_cols = ['model', 'improvement_%', 'folds_better', 'n_tests_sig',\n",
    "                'dm_p', 'sign_p', 'wilcoxon_p', 'bootstrap_p', 'clarkwest_p']\n",
    "print(\"\\n\" + df_tests_k6_d0[display_cols].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Significance Summary (p < 0.05):\")\n",
    "print(\"=\"*80)\n",
    "sig_summary_k6 = df_tests_k6_d0[['model', 'dm_sig', 'sign_sig', 'wilcoxon_sig', \n",
    "                               'bootstrap_sig', 'clarkwest_sig', 'n_tests_sig']].head(10)\n",
    "print(\"\\n\" + sig_summary_k6.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STATISTICAL TEST RESULTS: K=25 (Top 10 Models)\n",
      "================================================================================\n",
      "\n",
      "          model  improvement_% folds_better  n_tests_sig     dm_p   sign_p  wilcoxon_p  bootstrap_p  clarkwest_p\n",
      "    K25_T10_T20       4.679384         9/10            5 0.001045 0.010742    0.000226        0.002     0.000162\n",
      "        K25_T10       1.019130         8/10            4 0.016551 0.054688    0.005099        0.015     0.008838\n",
      "K25_T10_T17_T24       2.677354         8/10            4 0.001396 0.054688    0.003792        0.001     0.000193\n",
      "    K25_T10_T17       1.199070         8/10            4 0.010514 0.054688    0.021097        0.006     0.003880\n",
      "        K25_T24       0.537292         8/10            4 0.047955 0.054688    0.011603        0.028     0.036504\n",
      "    K25_T10_T24       2.309901         8/10            4 0.004021 0.054688    0.001196        0.002     0.000995\n",
      "    K25_T17_T24       0.497075         8/10            3 0.039379 0.054688    0.113254        0.022     0.020340\n",
      " K25_T1_T10_T24       2.636790         7/10            1 0.153663 0.171875    0.071174        0.133     0.048530\n",
      "         K25_T1      -0.629210         7/10            0 0.607031 0.171875    0.492047        0.644     0.479096\n",
      "    K25_T11_T20       0.737256         7/10            0 0.172061 0.171875    0.586809        0.155     0.134056\n",
      "\n",
      "================================================================================\n",
      "Significance Summary (p < 0.05):\n",
      "================================================================================\n",
      "\n",
      "          model  dm_sig  sign_sig  wilcoxon_sig  bootstrap_sig  clarkwest_sig  n_tests_sig\n",
      "    K25_T10_T20    True      True          True           True           True            5\n",
      "        K25_T10    True     False          True           True           True            4\n",
      "K25_T10_T17_T24    True     False          True           True           True            4\n",
      "    K25_T10_T17    True     False          True           True           True            4\n",
      "        K25_T24    True     False          True           True           True            4\n",
      "    K25_T10_T24    True     False          True           True           True            4\n",
      "    K25_T17_T24    True     False         False           True           True            3\n",
      " K25_T1_T10_T24   False     False         False          False           True            1\n",
      "         K25_T1   False     False         False          False          False            0\n",
      "    K25_T11_T20   False     False         False          False          False            0\n"
     ]
    }
   ],
   "source": [
    "# K=25 Results\n",
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL TEST RESULTS: K=25 (Top 10 Models)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + df_tests_k25_d0[display_cols].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Significance Summary (p < 0.05):\")\n",
    "print(\"=\"*80)\n",
    "sig_summary_k25 = df_tests_k25_d0[['model', 'dm_sig', 'sign_sig', 'wilcoxon_sig',\n",
    "                                 'bootstrap_sig', 'clarkwest_sig', 'n_tests_sig']].head(10)\n",
    "print(\"\\n\" + sig_summary_k25.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Interpretation and Recommendations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interpretation(df_tests, model_family):\n",
    "    \"\"\"\n",
    "    Generate interpretation and recommended narrative\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"INTERPRETATION: {model_family}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Best model by evidence\n",
    "    best_model = df_tests.iloc[0]\n",
    "    \n",
    "    print(f\"\\n[1] BEST MODEL: {best_model['model']}\")\n",
    "    print(f\"    RMSE Improvement: {best_model['improvement_%']:.1f}%\")\n",
    "    print(f\"    Folds better: {best_model['folds_better']}\")\n",
    "    print(f\"    Tests significant: {best_model['n_tests_sig']}/5\")\n",
    "    print(f\"\\n    P-values:\")\n",
    "    print(f\"      Diebold-Mariano:  {best_model['dm_p']:.4f} {'✓' if best_model['dm_sig'] else '✗'}\")\n",
    "    print(f\"      Sign Test:        {best_model['sign_p']:.4f} {'✓' if best_model['sign_sig'] else '✗'}\")\n",
    "    print(f\"      Wilcoxon:         {best_model['wilcoxon_p']:.4f} {'✓' if best_model['wilcoxon_sig'] else '✗'}\")\n",
    "    print(f\"      Bootstrap DM:     {best_model['bootstrap_p']:.4f} {'✓' if best_model['bootstrap_sig'] else '✗'}\")\n",
    "    print(f\"      Clark-West:       {best_model['clarkwest_p']:.4f} {'✓' if best_model['clarkwest_sig'] else '✗'}\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    n_models = len(df_tests)\n",
    "    n_any_sig = (df_tests['n_tests_sig'] > 0).sum()\n",
    "    n_majority_sig = (df_tests['n_tests_sig'] >= 3).sum()\n",
    "    n_all_sig = (df_tests['n_tests_sig'] == 5).sum()\n",
    "    \n",
    "    print(f\"\\n[2] OVERALL ASSESSMENT\")\n",
    "    print(f\"    Models tested: {n_models}\")\n",
    "    print(f\"    Models with ANY significant test: {n_any_sig}/{n_models} ({n_any_sig/n_models*100:.0f}%)\")\n",
    "    print(f\"    Models with MAJORITY significant (3+/5): {n_majority_sig}/{n_models} ({n_majority_sig/n_models*100:.0f}%)\")\n",
    "    print(f\"    Models with ALL tests significant (5/5): {n_all_sig}/{n_models}\")\n",
    "    \n",
    "    avg_improvement = df_tests.head(5)['improvement_%'].mean()\n",
    "    print(f\"\\n    Average improvement (top 5): {avg_improvement:.1f}%\")\n",
    "    \n",
    "    # Test agreement\n",
    "    print(f\"\\n[3] TEST AGREEMENT (Top 10 models)\")\n",
    "    top_10 = df_tests.head(10)\n",
    "    print(f\"    DM test:         {top_10['dm_sig'].sum()}/10 significant\")\n",
    "    print(f\"    Sign test:       {top_10['sign_sig'].sum()}/10 significant\")\n",
    "    print(f\"    Wilcoxon test:   {top_10['wilcoxon_sig'].sum()}/10 significant\")\n",
    "    print(f\"    Bootstrap DM:    {top_10['bootstrap_sig'].sum()}/10 significant\")\n",
    "    print(f\"    Clark-West:      {top_10['clarkwest_sig'].sum()}/10 significant\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 5: Statistical Tests for d=1 (Causal Robustness)\n",
    "\n",
    "Test if improvements persist when using ARIMAX(2,1,0) with differencing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5.1: K=6 Tests (d=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "K=6 STATISTICAL TESTS (d=1)\n",
      "================================================================================\n",
      "\n",
      "Testing 10 models against baseline...\n",
      "\n",
      "[ 1/10] Testing K6_T3                     → 0/5 tests significant\n",
      "[ 2/10] Testing K6_T2_T3                  → 0/5 tests significant\n",
      "[ 3/10] Testing K6_T2_T5                  → 0/5 tests significant\n",
      "[ 4/10] Testing K6_T3_T5                  → 0/5 tests significant\n",
      "[ 5/10] Testing K6_T4_T5                  → 0/5 tests significant\n",
      "[ 6/10] Testing K6_T1_T2_T3               → 0/5 tests significant\n",
      "[ 7/10] Testing K6_T2_T3_T5               → 0/5 tests significant\n",
      "[ 8/10] Testing K6_T2_T4_T5               → 0/5 tests significant\n",
      "[ 9/10] Testing K6_T1_T2_T3_T5            → 0/5 tests significant\n",
      "[10/10] Testing K6_T2_T3_T4_T5            → 0/5 tests significant\n",
      "\n",
      " K=6 d=1 testing complete\n",
      "  Models with ANY significant test: 0/10\n",
      "  Models with MAJORITY significant (3+): 0/10\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"K=6 STATISTICAL TESTS (d=1)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTesting {len(results_k6_d1)-1} models against baseline...\\n\")\n",
    "\n",
    "test_results_k6_d1 = []\n",
    "baseline_k6_d1 = results_k6_d1['Baseline']\n",
    "\n",
    "for i, (model_name, model_results) in enumerate(results_k6_d1.items(), 1):\n",
    "    if model_name == 'Baseline':\n",
    "        continue\n",
    "    \n",
    "    print(f\"[{i-1:2d}/{len(results_k6_d1)-1}] Testing {model_name:25s}\", end=\" \")\n",
    "    \n",
    "    test_result = run_all_tests(baseline_k6_d1, model_results, model_name)\n",
    "    test_results_k6_d1.append(test_result)\n",
    "    \n",
    "    sig_count = test_result['n_tests_sig']\n",
    "    print(f\"→ {sig_count}/5 tests significant\")\n",
    "\n",
    "df_tests_k6_d1 = pd.DataFrame(test_results_k6_d1)\n",
    "df_tests_k6_d1 = df_tests_k6_d1.sort_values('n_tests_sig', ascending=False)\n",
    "\n",
    "print(f\"\\n K=6 d=1 testing complete\")\n",
    "print(f\"  Models with ANY significant test: {(df_tests_k6_d1['n_tests_sig'] > 0).sum()}/{len(df_tests_k6_d1)}\")\n",
    "print(f\"  Models with MAJORITY significant (3+): {(df_tests_k6_d1['n_tests_sig'] >= 3).sum()}/{len(df_tests_k6_d1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5.2: K=25 Tests (d=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "K=25 STATISTICAL TESTS (d=1)\n",
      "================================================================================\n",
      "\n",
      "Testing 10 models against baseline...\n",
      "\n",
      "[ 1/10] Testing K25_T9                    → 0/5 tests significant\n",
      "[ 2/10] Testing K25_T10                   → 0/5 tests significant\n",
      "[ 3/10] Testing K25_T15                   → 0/5 tests significant\n",
      "[ 4/10] Testing K25_T20                   → 0/5 tests significant\n",
      "[ 5/10] Testing K25_T24                   → 0/5 tests significant\n",
      "[ 6/10] Testing K25_T10_T24               → 0/5 tests significant\n",
      "[ 7/10] Testing K25_T10_T20               → 0/5 tests significant\n",
      "[ 8/10] Testing K25_T20_T24               → 0/5 tests significant\n",
      "[ 9/10] Testing K25_T13_T24               → 0/5 tests significant\n",
      "[10/10] Testing K25_T10_T17_T24           → 0/5 tests significant\n",
      "\n",
      " K=25 d=1 testing complete\n",
      "  Models with ANY significant test: 0/10\n",
      "  Models with MAJORITY significant (3+): 0/10\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"K=25 STATISTICAL TESTS (d=1)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTesting {len(results_k25_d1)-1} models against baseline...\\n\")\n",
    "\n",
    "test_results_k25_d1 = []\n",
    "baseline_k25_d1 = results_k25_d1['Baseline']\n",
    "\n",
    "for i, (model_name, model_results) in enumerate(results_k25_d1.items(), 1):\n",
    "    if model_name == 'Baseline':\n",
    "        continue\n",
    "    \n",
    "    print(f\"[{i-1:2d}/{len(results_k25_d1)-1}] Testing {model_name:25s}\", end=\" \")\n",
    "    \n",
    "    test_result = run_all_tests(baseline_k25_d1, model_results, model_name)\n",
    "    test_results_k25_d1.append(test_result)\n",
    "    \n",
    "    sig_count = test_result['n_tests_sig']\n",
    "    print(f\"→ {sig_count}/5 tests significant\")\n",
    "\n",
    "df_tests_k25_d1 = pd.DataFrame(test_results_k25_d1)\n",
    "df_tests_k25_d1 = df_tests_k25_d1.sort_values('n_tests_sig', ascending=False)\n",
    "\n",
    "print(f\"\\n K=25 d=1 testing complete\")\n",
    "print(f\"  Models with ANY significant test: {(df_tests_k25_d1['n_tests_sig'] > 0).sum()}/{len(df_tests_k25_d1)}\")\n",
    "print(f\"  Models with MAJORITY significant (3+): {(df_tests_k25_d1['n_tests_sig'] >= 3).sum()}/{len(df_tests_k25_d1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 6: Comparison - d=0 vs d=1\n",
    "\n",
    "## Critical Question: Which models are significant in BOTH specifications?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARISON: SIGNIFICANCE IN d=0 vs d=1\n",
      "================================================================================\n",
      "\n",
      " K=6 COMPARISON\n",
      "--------------------------------------------------------------------------------\n",
      "Significant in d=0 (Forecasting):     43 models\n",
      "Significant in d=1 (Causality):       0 models\n",
      "Significant in BOTH:                  0 models\n",
      "Significant in d=0 only:              43 models\n",
      "Significant in d=1 only:              0 models\n",
      "\n",
      "Models significant in BOTH (strongest evidence):\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARISON: SIGNIFICANCE IN d=0 vs d=1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For K=6, compare which models are significant in both\n",
    "\n",
    "print(\"\\n K=6 COMPARISON\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Get significant models from each (majority of tests significant: >= 3 out of 5)\n",
    "sig_d0 = set(df_tests_k6_d0[df_tests_k6_d0['n_tests_sig'] >= 3]['model'].values)\n",
    "sig_d1 = set(df_tests_k6_d1[df_tests_k6_d1['n_tests_sig'] >= 3]['model'].values)\n",
    "\n",
    "# Find overlap\n",
    "sig_both = sig_d0.intersection(sig_d1)\n",
    "sig_d0_only = sig_d0 - sig_d1\n",
    "sig_d1_only = sig_d1 - sig_d0\n",
    "\n",
    "print(f\"Significant in d=0 (Forecasting):     {len(sig_d0)} models\")\n",
    "print(f\"Significant in d=1 (Causality):       {len(sig_d1)} models\")\n",
    "print(f\"Significant in BOTH:                  {len(sig_both)} models\")\n",
    "print(f\"Significant in d=0 only:              {len(sig_d0_only)} models\")\n",
    "print(f\"Significant in d=1 only:              {len(sig_d1_only)} models\")\n",
    "\n",
    "print(f\"\\nModels significant in BOTH (strongest evidence):\")\n",
    "for model in list(sig_both)[:10]:  # Top 10\n",
    "    imp_d0 = df_tests_k6_d0[df_tests_k6_d0['model'] == model]['improvement_%'].values[0]\n",
    "    imp_d1 = df_tests_k6_d1[df_tests_k6_d1['model'] == model]['improvement_%'].values[0]\n",
    "    print(f\"  {model:25s} d=0: {imp_d0:6.2f}%  d=1: {imp_d1:6.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9: Export Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESULTS SAVED\n",
      "================================================================================\n",
      "✓ results/statistical_tests_k6.csv\n",
      "✓ results/statistical_tests_k25.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save test results\n",
    "df_tests_k6_d0.to_csv('results/statistical_tests_k6.csv', index=False)\n",
    "df_tests_k25_d0.to_csv('results/statistical_tests_k25.csv', index=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESULTS SAVED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ results/statistical_tests_k6.csv\")\n",
    "print(f\"✓ results/statistical_tests_k25.csv\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
